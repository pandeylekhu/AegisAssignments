{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "LabEncoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data = pd.read_csv('Train_UWu5bXk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanbytype=sales_data.groupby('Item_Type').Item_Weight.transform('mean')\n",
    "sales_data['Item_Weight'].fillna(meanbytype,inplace=True)\n",
    "sales_data['Outlet_Size'].fillna('Missing',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the age of Outlet\n",
    "import datetime \n",
    "datetime.datetime.now().year\n",
    "sales_data['Outlet_Age']=sales_data.Outlet_Establishment_Year.sub(datetime.datetime.now().year).abs()\n",
    "#Encode outlet size ordinally\n",
    "scale_size={'Missing':1,'Small':1,'Medium':2,'High':3}\n",
    "sales_data['Outlet_Size']=sales_data['Outlet_Size'].replace(scale_size)\n",
    "#clean fat content column\n",
    "sales_data.Item_Fat_Content=sales_data.Item_Fat_Content.str.upper()\n",
    "scale_fat_content={'LOW FAT':0,'LF':0,'REGULAR':1,'REG':1}\n",
    "sales_data['Item_Fat_Content']=sales_data['Item_Fat_Content'].replace(scale_fat_content)\n",
    "sales_data.Outlet_Location_Type=pd.to_numeric(sales_data.Outlet_Location_Type.str.replace('Tier ',''))\n",
    "scale_fat_outlet_type={'Grocery Store':0,'Supermarket Type1':1,'Supermarket Type2':2,'Supermarket Type3':3}\n",
    "sales_data['Outlet_Type']=sales_data['Outlet_Type'].replace(scale_fat_outlet_type)\n",
    "# sales_data.Item_Type=LabEncoder.fit_transform(sales_data.Item_Type)\n",
    "sales_data=pd.concat([sales_data,pd.get_dummies(sales_data.Item_Type,prefix='Item_Type')],axis=1)\n",
    "# sales_data=pd.concat([sales_data,pd.get_dummies(sales_data.Item_Type,prefix='Item_Identifier')],axis=1)\n",
    "sales_data['Item_Ident_prefix']=sales_data.Item_Identifier.str.slice(start=0,stop=2)\n",
    "sales_data=pd.concat([sales_data,pd.get_dummies(sales_data.Item_Ident_prefix,prefix='Item_Identifier')],axis=1)\n",
    "# sales_data['Item_Ident_post']=sales_data.Item_Identifier.str.slice(start=2,stop=3)\n",
    "sales_data=pd.concat([sales_data,pd.get_dummies(sales_data.Outlet_Identifier,prefix='Outlet_Identifier')],axis=1)\n",
    "sales_data=sales_data.drop(['Item_Identifier','Outlet_Establishment_Year','Item_Type','Outlet_Identifier','Item_Ident_prefix'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=sales_data['Item_Outlet_Sales'].values\n",
    "X=sales_data.drop('Item_Outlet_Sales',axis=1).values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "X_std=ss.fit_transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X_std,y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error 1121.2164292578823 Test Error 1147.723288248753\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(xtrain,ytrain)\n",
    "pred_train=linreg.predict(xtrain)\n",
    "pred_test=linreg.predict(xtest)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_rmse_train = np.sqrt(mean_squared_error(ytrain,pred_train))\n",
    "lin_rmse_test=np.sqrt(mean_squared_error(ytest,pred_test))\n",
    "print(\"Train Error\",lin_rmse_train,\"Test Error\",lin_rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf=PolynomialFeatures(3)\n",
    "X_Poly=pf.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error 992.1308112646474 Test Error 131009410555358.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(X_Poly,y,test_size=0.25,random_state=0)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(xtrain,ytrain)\n",
    "pred_train=linreg.predict(xtrain)\n",
    "pred_test=linreg.predict(xtest)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "lin_rmse_train = np.sqrt(mean_squared_error(ytrain,pred_train))\n",
    "lin_rmse_test=np.sqrt(mean_squared_error(ytest,pred_test))\n",
    "print(\"Train Error\",lin_rmse_train,\"Test Error\",lin_rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19950 1027.4723944462469 1108.9681738592005 81.49577941295365\n",
      "19975 1027.5016424686196 1108.9683429582972 81.46670048967758\n",
      "19999 1027.529701481023 1108.96853084639 81.43882936536693\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "alphas=[19950,19975,19999]#,20300,20400]\n",
    "df=pd.DataFrame(columns=['Alpha','train_error','test_error'])\n",
    "for alpha_ in alphas:\n",
    "    rr=Ridge(alpha=alpha_)\n",
    "    rr.fit(xtrain,ytrain)\n",
    "    \n",
    "    pred_train=rr.predict(xtrain)\n",
    "    pred_test=rr.predict(xtest)\n",
    "    lin_rmse_train = np.sqrt(mean_squared_error(ytrain,pred_train))\n",
    "    lin_rmse_test=np.sqrt(mean_squared_error(ytest,pred_test))\n",
    "#     tup=[]\n",
    "#     tup=[alpha_,lin_rmse_train,lin_rmse_test,lin_rmse_test-lin_rmse_train]\n",
    "    print(alpha_,lin_rmse_train,lin_rmse_test,lin_rmse_test-lin_rmse_train)\n",
    "#     df.append(pd.DataFrame(tup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1060.717047056385 1087.6663367940478 26.949289737662866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridg=Ridge(alpha=19950)\n",
    "ridg.fit(xtrain,ytrain)\n",
    "pred_train=rr.predict(xtrain)\n",
    "pred_test=rr.predict(xtest)\n",
    "lin_rmse_train = np.sqrt(mean_squared_error(ytrain,pred_train))\n",
    "lin_rmse_test=np.sqrt(mean_squared_error(ytest,pred_test))\n",
    "print(lin_rmse_train,lin_rmse_test,lin_rmse_test-lin_rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 1056.0618365913765 1087.2977423929847 31.23590580160817\n",
      "60 1057.217082270026 1087.2343464675605 30.017264197534587\n",
      "70 1059.5707672218457 1087.4210161689964 27.850248947150703\n",
      "75 1060.717047056385 1087.6663367940478 26.949289737662866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "alphas=[55,60,70,75]\n",
    "df=pd.DataFrame(columns=['Alpha','train_error','test_error'])\n",
    "for alpha_ in alphas:\n",
    "    rr=Lasso(alpha=alpha_)\n",
    "    rr.fit(xtrain,ytrain)\n",
    "    \n",
    "    pred_train=rr.predict(xtrain)\n",
    "    pred_test=rr.predict(xtest)\n",
    "    lin_rmse_train = np.sqrt(mean_squared_error(ytrain,pred_train))\n",
    "    lin_rmse_test=np.sqrt(mean_squared_error(ytest,pred_test))\n",
    "#     tup=[]\n",
    "#     tup=[alpha_,lin_rmse_train,lin_rmse_test,lin_rmse_test-lin_rmse_train]  \n",
    "    print(alpha_,lin_rmse_train,lin_rmse_test,lin_rmse_test-lin_rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1045.5838325675827 1113.5057794149636 67.92194684738092\n",
      "0 1039.2572244800497 1108.8718191922974 69.61459471224771\n",
      "0 1032.1284433128922 1105.4215311823014 73.29308786940919\n",
      "0 1022.7751891706926 1104.411759016405 81.63656984571253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1002.8599016492403 1122.7512736894093 119.89137204016902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "#alphas=[5.5,5.75,6,6.25,6.50,6.75,7]\n",
    "l1_ratios=[0,0.25,0.5,0.75,1]\n",
    "df=pd.DataFrame(columns=['Alpha','train_error','test_error'])\n",
    "#for alpha_ in alphas:\n",
    "    #rr=ElasticNet(alpha=alpha_)\n",
    "for l1_ratio_ in l1_ratios:\n",
    "    rr=ElasticNet(alpha=6,l1_ratio=l1_ratio_)\n",
    "    rr.fit(xtrain,ytrain)\n",
    "    \n",
    "    pred_train=rr.predict(xtrain)\n",
    "    pred_test=rr.predict(xtest)\n",
    "    lin_rmse_train = np.sqrt(mean_squared_error(ytrain,pred_train))\n",
    "    lin_rmse_test=np.sqrt(mean_squared_error(ytest,pred_test))\n",
    "#     tup=[]\n",
    "#     tup=[alpha_,lin_rmse_train,lin_rmse_test,lin_rmse_test-lin_rmse_train]\n",
    "#     df=df.append({'Alpha':alpha_,'train_error':lin_rmse_train,'test_error':lin_rmse_test},ignore_index=True)\n",
    "#     print(alpha_,lin_rmse_train,lin_rmse_test,lin_rmse_test-lin_rmse_train)\n",
    "    print(l1_ratio_,lin_rmse_train,lin_rmse_test,lin_rmse_test-lin_rmse_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "ridg=ElasticNet(alpha=19950)\n",
    "ridg.fit(xtrain,ytrain)\n",
    "pred_train=rr.predict(xtrain)\n",
    "pred_test=rr.predict(xtest)\n",
    "lin_rmse_train = np.sqrt(mean_squared_error(ytrain,pred_train))\n",
    "lin_rmse_test=np.sqrt(mean_squared_error(ytest,pred_test))\n",
    "print(lin_rmse_train,lin_rmse_test,lin_rmse_test-lin_rmse_train)\n",
    "ridge.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "sales_data_test=pd.read_csv('Test_u94Q5KV.csv')\n",
    "sales_data_tmp=sales_data_test\n",
    "meanbytype=sales_data_test.groupby('Item_Type').Item_Weight.transform('mean')\n",
    "sales_data_test['Item_Weight'].fillna(meanbytype,inplace=True)\n",
    "sales_data_test['Outlet_Size'].fillna('Missing',inplace=True)\n",
    "# get the age of Outlet\n",
    "import datetime \n",
    "datetime.datetime.now().year\n",
    "sales_data_test['Outlet_Age']=sales_data_test.Outlet_Establishment_Year.sub(datetime.datetime.now().year).abs()\n",
    "#Encode outlet size ordinally\n",
    "scale_size={'Missing':1,'Small':1,'Medium':2,'High':3}\n",
    "sales_data_test['Outlet_Size']=sales_data_test['Outlet_Size'].replace(scale_size)\n",
    "#clean fat content column\n",
    "sales_data_test.Item_Fat_Content=sales_data_test.Item_Fat_Content.str.upper()\n",
    "scale_fat_content={'LOW FAT':0,'LF':0,'REGULAR':1,'REG':1}\n",
    "sales_data_test['Item_Fat_Content']=sales_data_test['Item_Fat_Content'].replace(scale_fat_content)\n",
    "sales_data_test.Outlet_Location_Type=pd.to_numeric(sales_data_test.Outlet_Location_Type.str.replace('Tier ',''))\n",
    "scale_fat_outlet_type={'Grocery Store':0,'Supermarket Type1':1,'Supermarket Type2':2,'Supermarket Type3':3}\n",
    "sales_data_test['Outlet_Type']=sales_data_test['Outlet_Type'].replace(scale_fat_outlet_type)\n",
    "# sales_data_test.Item_Type=LabEncoder.fit_transform(sales_data_test.Item_Type)\n",
    "sales_data_test=pd.concat([sales_data_test,pd.get_dummies(sales_data_test.Item_Type,prefix='Item_Type')],axis=1)\n",
    "# sales_data_test=pd.concat([sales_data_test,pd.get_dummies(sales_data_test.Item_Type,prefix='Item_Identifier')],axis=1)\n",
    "sales_data_test['Item_Ident_prefix']=sales_data_test.Item_Identifier.str.slice(start=0,stop=2)\n",
    "sales_data_test=pd.concat([sales_data_test,pd.get_dummies(sales_data_test.Item_Ident_prefix,prefix='Item_Identifier')],axis=1)\n",
    "# sales_data_test['Item_Ident_post']=sales_data_test.Item_Identifier.str.slice(start=2,stop=3)\n",
    "sales_data_test=pd.concat([sales_data_test,pd.get_dummies(sales_data_test.Outlet_Identifier,prefix='Outlet_Identifier')],axis=1)\n",
    "sales_data_test=sales_data_test.drop(['Item_Identifier','Outlet_Establishment_Year','Item_Type','Outlet_Identifier','Item_Ident_prefix'],axis=1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "X_std=ss.fit_transform(sales_data_test)\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pf=PolynomialFeatures(3)\n",
    "X_Poly_test=pf.fit_transform(X_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1036.4169749579305 1105.6389358375316 69.22196087960106\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "ridg=Lasso(alpha=60)\n",
    "ridg.fit(xtrain,ytrain)\n",
    "pred_train=rr.predict(xtrain)\n",
    "pred_test=rr.predict(xtest)\n",
    "lin_rmse_train = np.sqrt(mean_squared_error(ytrain,pred_train))\n",
    "lin_rmse_test=np.sqrt(mean_squared_error(ytest,pred_test))\n",
    "print(lin_rmse_train,lin_rmse_test,lin_rmse_test-lin_rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_data_tmp['Item_Outlet_Sales']=ridg.predict(X_Poly_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_Output=sales_data_tmp[['Item_Identifier','Outlet_Identifier','Item_Outlet_Sales']]\n",
    "final_Output.to_csv('BigDataMart_Predicted.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
